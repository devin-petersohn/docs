% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{amsmath}
%
\begin{document}
%
\frontmatter          % for the preliminaries
%
\pagestyle{headings}  % switches on printing of running heads
\addtocmark{Bayesian Read-Error Correction}
\mainmatter              % start of the contributions
%
\title{A Generative Model for Distributed \\ Read-Error Correction}
%
\titlerunning{Bayesian Read-Error Correction}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Frank~Austin~Nothaft, Anthony~D.~Joseph, \and David~A.~Patterson}
%
\authorrunning{Nothaft et al.} % abbreviated author list (for running head)
%
\institute{Department of Electrical Engineering and Computer Sciences\\
University of California, Berkeley \\ 
Berkeley, CA 94720, USA \\
\email{\{fnothaft, adj, pattrsn\}@berkeley.edu}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
Read error correction is a key step in many genome assembly protocols, but is computationally
expensive. Recent papers have proposed several strategies for approximating steps in the error
correction process. In this paper, we derive a rigorous generative model for identifying and correcting
errors in short reads. We implement our algorithm using the Apache Spark distributed computing
platform. Our implementation demonstrates a performant and exact approach to read error correction
that can scale efficiently to mammalian genomes.

\keywords{genome assembly, read error correction, distributed computing}
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Read error correction is a key step in most genome assembly protocols, but is computationally
expensive~\cite{kelley10}. Recent work has explored mechanisms for performing error correction with
probabilistic data structures which consume less memory~\cite{song14,shi10,liu13,heo14}. However,
we assert that these techniques are unnecessary with the rise of distributed, in-memory computing
frameworks that scale easily on commodity hardware~\cite{zaharia10}.

In this paper, we present a distributed algorithm for performing read error correction, which is built using
the ADAM libraries for distributed genomics~\cite{massie13}. Our algorithm trains a model for read errors
using the abundance spectrum of quality score weighted $k$-mers (known as $q$-mers~\cite{kelley10}).
Given these probabilities, we estimate transition probabilities across classes which contain correlated
errors. Finally, per read, we perform error correction via a coordinate ascent process. As our algorithms
are implemented on top of the Apache Spark in-memory MapReduce system~\cite{zaharia10}, we are
able to achieve both scale up and scale out performance. Our software is open source under the Apache
2 license.

We make the following contributions:

\begin{enumerate}
\item We implement a MapReduce based, in-memory $k$/$q$-mer counting engine.
\item We demonstrate a probabilistically rigorous, generative model for read error correction.
\item Our model is implemented in a scalable fashion on an efficient, MapReduce engine.
\end{enumerate}

\section{Generative Model for Error Correction}
\label{sec:generative-model}

\subsection{Erroneous $k$-mer Detection}
\label{sec:detection}

To detect erroneous $k$-mers, we use the $q$-mer construct which was introduced by Kelley et
al.~\cite{kelley10}\footnote{$q$-mers are $k$-mers which are weighted by the quality scores of the
bases seen in the sequenced read.} We apply an unsupervised clustering model to learn the
classifications of $q$-mers. For a sample with ploidy of $m$, we model $q$-mers as being drawn from a
selection of $m + 1$ Gamma distributions. $m - 1$ of these distributions model ``true'' $q$-mers which are
drawn from heterozygous sites, one distribution models ``true'' $q$-mers drawn from homozygous sites,
and one distribution models erroneous $q$-mers. While prior work by Kelley et al.~\cite{kelley10} has
used the Normal distribution to model the counts of ``true'' $q$-mers, it is preferable to use the Gamma
distribution, whose support is limited to $[0, \infty)$.

We describe the process we use for counting $q$-mers in~\S\ref{sec:distributed-kmer-counting}. Once
we have counted $q$-mers, we then fit our mixture model using the expectation-\linebreak
maximization~(EM) algorithm introduced by Almhana et al.~\cite{almhana06} We considered the
optimized algorithm for fitting mixtures of Gammas that was proposed by Schwander and
Nielsen~\cite{schwander13}, but chose the Almhana EM algorithm because the Schwander $k$-MLE
algorithm is slower for mixtures that contain fewer than eight components. We describe the
implementation of this algorithm in~\S\ref{sec:distributed-em}.

Once the mixture model has been fit, each $k$-mer can be assigned an error probability. This
probability is given in equation~\ref{eq:p-err}, and is defined by the softmax likelihood that a $k$-mer is
drawn from the error distribution, given the $q$ weight of the $k$-mer.

\begin{equation}
\label{eq:p-err}
P(k \text{ is erroneous}) = \frac{\mathcal{L}(s = 0 | k)}{\sum_{i = 0}^{m + 1} \mathcal{L}(s = i | k)}
\end{equation}

Once the error probabilities have been calculated for all $k$-mers, we then filter the set of $k$-mers
to obtain the set of trusted $k$-mers. We apply the following filters, and place all $k$-mers that satisfy
these filters into a trie:

\begin{enumerate}
\item The $k$-mer is kept if it's error probability is below a user provided error threshold, and
\item The $k$-mer does not contain any IUPAC disambiguation codes.
\end{enumerate}

\subsection{Base Transition Probability}
\label{sec:transition-probability}

Due to well-known biases in the sequencing process, the four nucleotides have different probabilities
of being sequenced incorrectly. Errors are known to be correlated within specific nucleotides, the
position of the base in the read, and empirical quality score values. These three \emph{covariates} are
used in the GATK's base quality score recalibration~(BQSR) process which measures the ``true'' error
probability that corresponds to a base quality score~\cite{depristo11}.

While base quality scores are a useful prior for the GATK's main goal~(specifically, variant calling),
their binary error/success nature is not as useful of a prior for read error correction. Instead, since we
are trying to predict whether a true base $b$ was incorrectly sequenced as $b'$, where $b, b' \in
\{ \text{A}, \text{C}, \text{G}, \text{T} \}$\footnote{In practice, the observed base, $b'$, may be
represented by any of the IUPAC base disambiguation codes. While we handle these cases in our
implementation, we do not include them here for notational simplicity. The corrected base, $b$, is
constrained to not be a disambiguation code.}, we desire our prior to be the transition probabilities from
$b' \rightarrow b$. These transition probabilities can be represented by categorical random variables
with four categories. We want to estimate these distributions per error covariate, where the error
covariate is defined by the sequenced base, the empirical base quality score, and the position of the
base in the read.

The transition probability for error covariate $C_{b', i, b}$ can be estimated via maximum likelihood.
Specifically, for each sequenced base $b'$ at position $i$ in the read, we can define the likelihood that
this base was actually $b$ by looking at the error probabilities of all $k$-mers that cover this base.

\begin{equation}
\label{eq:base-error}
\mathcal{L}(b, i) = \frac{\prod_{j = 1}^{k} 1 - P(\text{kmer}_j^{b, i} \text{ is erroneous})}{\sum_{\hat{b} =
\{A, C, G, T\}} \prod_{j = 1}^{k} 1 - P(\text{kmer}_j^{\hat{b}, i} \text{ is erroneous})}
\end{equation}

In equation~\ref{eq:base-error}, we use $\text{kmer}_j^{b, i}$ as a function that appropriately
substitutes base $b$ into the $j$th $k$-mer that covers the base at position $i$. Also, note in practice
that bases at the start and end of the read will not be covered by $k$ $k$-mers; for example, the first
base of each read is covered by a single $k$-mer. The $P(k\text{-mer is erroneous})$ probabilities
are evaluated using the trie collected by the erroneous $k$-mer detection process described
in~\S\ref{sec:detection}. We note that invalid $k$-mers are not present in that tree; when we search for
a $k$-mer that is not resident in the trie, we substitute the user provided probability cutoff as an upper
bound on the truth probability of that $k$-mer.

To achieve a most accurate estimate for the transition probabilities of error covariate $C_{b', i, b}$, we
would ideally run an EM algorithm over all bases in $C_{b', i, b}$. However, this is not easily tractable
as within a read, we cannot separately evaluate the transitions for bases $i - 1$, $i$, and $i + 1$. To
run such an EM algorithm, we would need to evaluate all transitions for all bases in all reads, which
would be computationally intractable; we discuss this in more detail in~\S\ref{sec:read-refinement}.
Instead, we estimate the transition probabilities by treating the probability estimates of all bases in
$C_{b', i, b}$ as the expected outcomes from multinomial trials, and apply an MLE estimator. This is
equivalent to running a single expectation phase of the canonical EM algorithm for a mixture of
categorical random variables.

\subsection{Read Refinement}
\label{sec:read-refinement}



\section{Implementation}
\label{sec:implementation}

\subsection{Distributed $k$-mer Counting}
\label{sec:distributed-kmer-counting}

\subsection{Distributed EM Algorithms}
\label{sec:distributed-em}

\section{Results}
\label{sec:results}

\section{Conclusion}
\label{sec:conclusion}

\bibliographystyle{splncs03}
\bibliography{read-error-correction}

\end{document}
