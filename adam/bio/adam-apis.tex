\documentclass{nature}
\usepackage{url}
\usepackage[style=nature,citetracker,defernumbers=true]{biblatex}

\makeatletter
\patchcmd{\blx@citation@entry}
  {\ifinlistcs{#1}{blx@segm@\the\c@refsection @\the\c@refsegment}
     {}
     {\listcsgadd{blx@segm@\the\c@refsection @\the\c@refsegment}{#1}}}
  {\ifboolexpr{ test {\blx@ifentryseen@global{#1}}
     or test {\ifinlistcs{#1}{blx@segm@\the\c@refsection @\the\c@refsegment}} }
     {}
     {\listcsgadd{blx@segm@\the\c@refsection @\the\c@refsegment}{#1}}}
  {}{}
\makeatother

\addbibresource{adam-apis.bib}

\title{ADAM Enables Large Scale Integrative Analyses Across Heterogenous Genomic Datasets}
\author{Frank~Austin~Nothaft$^1$, et al$^{1, 2, 3, 4, 5, 6}$}

\begin{document}

\maketitle

\begin{affiliations}
\item AMPLab, University of California, Berkeley, CA
\item Cloudera, Inc., San Francisco, CA
\item GenomeBridge, Cambridge, MA
\item Icahn School of Medicine at Mount Sinai, New York, NY
\item Genome Informatics Lab, University of Californa, Santa Cruz, CA
\item Microsoft Research, Redmond, WA
\end{affiliations}

\begin{abstract}

The detection and analysis of rare genomic events requires integrative analysis across
large cohorts with terabytes to petabytes of genomic data. Contemporary genomic analysis tools
have not been designed for this scale of data-intensive computing. In this paper, we present
ADAM, a library built on top of the popular Apache Spark distributed computing framework.
ADAM provides high level primitives that enable genomic analyses to be efficiently executed
across a large cluster of computers. Unlike other toolkits, ADAM is designed to easily enable
the mixing of different types and sources of genomic data. In this paper, we demonstrate ADAM
using several applications that process large genomic feature, genotype, and read datasets.
ADAM enables analyses to be seamlessly distributed across hundreds of nodes, while achieving a
66\% cost improvement over current toolkits.
\end{abstract}

\begin{refsegment}
\section{Introduction}
\label{sec:introduction}

\begin{enumerate}
\item A big driver for extensive sequencing is detecting low frequency genomic correlations
\begin{enumerate}
\item This necessitates the joint analysis/integration of large cohorts; these datasets are
frequently too large to process on a single machine
\item The GATK provides common primitives for constructing genomic analyses~\cite{mckenna10}, but
is difficult to run in a distributed setting
\item We want to leverage the past decade of industrial development of horizontally scalable
systems~\cite{zaharia10, dean08}
\item This approach has been successfully applied to neuroscience~\cite{freeman14}
\end{enumerate}
\item In ADAM, we provide abstractions for accessing and processing genomic data on a cluster
of commodity machines
\begin{enumerate}
\item We provide a programing framework that accelerates common genomic processing tasks, while
not limiting the algorithms that can be run
\item Algorithms are high level: shouldn't be concerned about data formats or the layout
of data on disk
\item Our approach enables the integration of many different types of genomic datasets, which
has been overlooked by current platforms~\cite{palsson10}
\end{enumerate}
\item By taking a ``ground up'' approach, we are able to improve analysis cost by 66\%
\begin{enumerate}
\item Bioinformatics analysis consumes up to 90\% of experiment costs~\cite{andrews14}
\item Our approach reduces cost by enabling the use of clusters of smaller machines, which are
more cost proportional~\cite{janapa10}
\end{enumerate}
\end{enumerate}

\section{Results}
\label{sec:results}

\subsection{Architecture}
\label{sec:architecture}

\begin{enumerate}
\item ADAM provides a collection-oriented view of genomic data
\begin{enumerate}
\item Operations are built on Spark's Resilient Distributed Dataset~(RDD, see~\cite{zaharia12})
abstraction, which provides a distributed, in-memory array
\item Collection-oriented view eliminates need for sort-order invariants; conflicting sort-order
invariants make it difficult to chain current genomic analysis tools together
\end{enumerate}
\item Processing pipelines are first class citizens in ADAM
\begin{enumerate}
\item Most genomic analyses are built as cascading pipelines
\item This has led to the design of many bioinformatics-specific workflow engines (e.g.,
Galaxy~\cite{goecks10})
\item Spark is natively designed to support chaining analysis steps with stronger
guarantees (fault tolerance, recomputation) by building a DAG~\cite{zaharia10}
\item Build \emph{workflows}, not \emph{workflow engines}
\end{enumerate}
\end{enumerate}

\subsection{Analyses}
\label{sec:analyses}

\begin{enumerate}
\item Variant Calling on 1000 Genomes
\item TCGA variant analysis
\end{enumerate}

\subsubsection{Scalable Variant Calling}
\label{sec:scalable-variant-calling}

\begin{enumerate}
\item ADAM enables both:
\begin{enumerate}
\item Rapid variant calling of a single sample
\item Joint variant calling across a large cohort
\end{enumerate}
\end{enumerate}

\subsubsection{TCGA Variant Analysis}
\label{sec:tcga-variant-analysis}

\begin{enumerate}
\item Variants can impact transcriptional regulation~\cite{weingarten14, levo14}
\item However, to study these impacts, we need to integrate across several
types of genomic data, which is difficult in conventional pipelines
\item In ADAM, this analysis is trival to do
\item We demonstrate how this can be done using the somatic variant callset from
The Cancer Genome Atlas~\cite{weinstein13}
\end{enumerate}

\section{Conclusion}
\label{sec:conclusion}

TBA

\printbibliography[segment=1]
\end{refsegment}

\begin{methods}
\begin{refsegment}

\section{Architecture}
\label{sec:supplement-architecture}

\begin{enumerate}
\item In prior work~\cite{nothaft15}, we have described the design approach that
inspired ADAM~\cite{zaharia10}
\item ADAM uses a commodity columnar storage format to store genomic data
\begin{enumerate}
\item Use the Apache Parquet~\cite{parquet} storage format, loosely based off of
Google Dremel~\cite{melnik10}
\item ADAM's formats are fully compatible with legacy genomics file formats
\item Parquet enables compression that is between BAM and CRAM~\cite{fritz11} without
incurring the costs and restrictions of reference-based compression
\item Additionally, we are able to apply these same compression techniques to
variant data, leading to a representation that is 66\% smaller than GZIP-ed VCF
\item This data is queryable from a variety of query engines~(Spark-SQL~\cite{armbrust15},
Impala~\cite{kornacker15})
\end{enumerate}
\item Many reference-based genomics algorithms can be implemented using the ``region join''
abstraction
\begin{enumerate}
\item At it's base, a ``region join'' is a relational join where key equality is determined
by the similarity of two keys in a genomic region space
\item This primitive can be used to implement many feature analysis algorithms~\cite{quinlan10}
\item To enable efficient implementations, we back our ``region join'' with a variety of
execution engines (e.g., broadcast, shuffle-based sort)
\end{enumerate}
\end{enumerate}

\section{Dataset Hosting}
\label{sec:dataset-hosting}

\begin{enumerate}
\item To make it easier to use ADAM, we've developed the eggo tool that ingests datasets
\begin{enumerate}
\item Dataset descriptions are stored using Data Protocols style schema~\cite{dataprotocols}
\item Datasets are converted and stored in Amazon S3 as a public resource
\item Tool makes it easy for people to use ADAM on common genomic datasets
\end{enumerate}
\item We use eggo to drive all of the analyses in this paper
\end{enumerate}

\section{Variant Calling Pipeline}
\label{sec:variant-calling}

\begin{enumerate}
\item Our variant calling pipeline is similar to the GATK's best practices
pipeline~\cite{auwera13}
\end{enumerate}

\subsection{Alignment}
\label{sec:alignment}

\begin{enumerate}
\item Short reads are aligned using the SNAP aligner~\cite{zaharia11}
\item Alignment is parallelized within avocado
\item To improve parallel efficiency of alignment, we:
\begin{enumerate}
\item Add custom code to perform multithreaded alignment index load from HDFS
\item Run SNAP as a daemon per machine, which allows amortization of index load costs
\end{enumerate}
\end{enumerate}

\subsection{Read Preprocessing Algorithms}
\label{sec:read-preprocessing-algorithm}

\begin{enumerate}
\item Run duplicate marking and base quality score recalibration
\item Details TBA; will talk about:
\begin{enumerate}
\item Efficient ways to parallelize quality score table aggregation
\item Benefits of fragment structure for duplicate marking
\end{enumerate}
\end{enumerate}

\subsection{Variant Calling Algorithm}
\label{sec:variant-calling-algorithm}

\begin{enumerate}
\item We use the avocado variant caller, which is built on ADAM, to call variants
\item avocado uses a local reassembly based approach for identifying variants
\begin{enumerate}
\item We make use of a complexity filtering process to limit the amount of reference
regions that are locally reassembled~\cite{bloniarz14}
\item Reassembler is de Bruijn graph based~\cite{pevzner01}
\end{enumerate}
\item avocado uses a biallelic statistical model
\begin{enumerate}
\item Based off of the statistical model in SAMtools mpileup~\cite{li11}
\item To improve numerical precision when integrating across large datasets, our
statistical model is evaluated in log space
\end{enumerate}
\end{enumerate}

\section{Regulatory Variant Analysis}
\label{sec:regulatory}

\begin{enumerate}
\item Use ``regulatory grammar'' described by Weingarten et al~\cite{weingarten14}
\item Approach:
\begin{enumerate}
\item Ingest TCGA somatic variant calls
\item Region join against ENCODE data and featurize variant calls into regulatory region
modifications
\end{enumerate}
\item Final analysis ``slices and dices'' in two ways:
\begin{enumerate}
\item Cluster genes
\item Cluster on samples
\item More details TBA
\end{enumerate}
\end{enumerate}

\printbibliography[segment=2]

\end{refsegment}
\end{methods}

\begin{addendum}
\item The authors would like to thank their many colleagues who provided feedback on early implementations of
ADAM, and on drafts of the manuscript. This research is supported in part by a National Science Foundation CISE Expeditions Award
[grant number CCF-1139158], Lawrence Berkeley National Lab [grant number 7076018], a Defense
Advanced Research Projects Agency XData Award [grant number FA8750-12-2-0331], a National
Institutes of Health BD2K Award [grant number 1-U54HG007990-01], a National Institutes of Health Cancer
Cloud Pilot Award [grant number HHSN261201400006C] and gifts from Amazon Web Services, Google,
SAP, The Thomas and Stacey Siebel Foundation, Adatao, Adobe, Apple, Inc., Blue Goji, Bosch, C3Energy,
Cisco, Cray, Cloudera, EMC, Ericsson, Facebook, Guavus, Huawei, Intel, Microsoft, NetApp, Pivotal,
Samsung, Splunk, Virdata, VMware, and Yahoo!. Author FAN is supported by a National Science
Foundation Graduate Research Fellowship.
\item[Competing Interests] The authors declare that they have no
competing financial interests.
\item[Correspondence] Correspondence and requests for materials should be addressed to
\linebreak F.A.N.~(email: fnothaft@berkeley.edu).
\end{addendum}

\end{document}
